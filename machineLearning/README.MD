````markdown
# ğŸ§  Cluster de Propostas com NLP + IA

Este repositÃ³rio contÃ©m o pipeline de **prÃ©-processamento textual**, **geraÃ§Ã£o de embeddings semÃ¢nticos** e **armazenamento vetorial com FAISS** para organizar as propostas do site **Brasil Participativo** por similaridade temÃ¡tica.

Nosso objetivo Ã© aplicar **Machine Learning e NLP** para agrupar automaticamente as propostas em **temas**, facilitando anÃ¡lises qualitativas e navegaÃ§Ã£o por parte da sociedade civil, pesquisadores e gestores pÃºblicos.

---

## ğŸ“Œ Etapas do Pipeline

```text
1. Web scraping das propostas  âœ…
2. PrÃ©-processamento textual    âœ…
3. GeraÃ§Ã£o de embeddings        âœ…
4. Armazenamento vetorial (FAISS) âœ…
5. ClusterizaÃ§Ã£o e visualizaÃ§Ã£o (em desenvolvimento)
6. Frontend e navegaÃ§Ã£o interativa (em breve)
````

---

## âš™ï¸ Como instalar as dependÃªncias

Este projeto usa um ambiente Python com bibliotecas especÃ­ficas para NLP e IA.

### â–¶ï¸ 1. Crie um ambiente virtual (recomendado)

```bash
python -m venv venv
source venv/bin/activate    # Linux/Mac
venv\Scripts\activate       # Windows
```

### â–¶ï¸ 2. Instale as dependÃªncias do projeto

```bash
pip install -r requirements.txt
```

> ğŸ’¡ Em sistemas Windows, pode ser necessÃ¡rio editar o `requirements.txt` e substituir `faiss-cpu` por `faiss-cpu-windows`.

---

## ğŸ§¹ Etapa 1 â€” PrÃ©-processamento Textual (`integracao.py`)

Esta etapa transforma os textos brutos em versÃµes padronizadas e limpas, prontas para processamento semÃ¢ntico.

### âœ¨ O que Ã© feito:

* RemoÃ§Ã£o de stopwords, pontuaÃ§Ã£o e links
* PadronizaÃ§Ã£o para caixa baixa
* RemoÃ§Ã£o de acentos
* ExtraÃ§Ã£o de listas textuais de colunas que armazenam mÃºltiplas propostas

### ğŸ“ Entrada esperada:

Um CSV contendo os textos brutos das propostas (como listas de strings):

```
['Proposta 1', 'Proposta 2', '...']
```

### â–¶ï¸ Como executar

```bash
python integracao.py
```

### ğŸ§¾ Resultado:

Gera o arquivo `propostas_limpa.csv`, onde cada linha contÃ©m **uma proposta jÃ¡ prÃ©-processada** na coluna `propostas_processadas`.

Como o projeto possui **mÃºltiplas Ã¡reas temÃ¡ticas e ciclos de scraping distintos**, os cÃ³digos de processamento sÃ£o executados **vÃ¡rias vezes** com diferentes conjuntos de dados. Para lidar com isso, adotamos uma estratÃ©gia **manual e descritiva**: antes de rodar o script, definimos **explicitamente qual arquivo serÃ¡ processado**, e ao final, salvamos o resultado com **nomes distintos** (ex: `propostas_meio_ambiente.csv`, `propostas_educacao.csv`), mantendo clareza e controle sobre os dados de saÃ­da.


---

## ğŸ§  Etapa 2 â€” GeraÃ§Ã£o de Embeddings com LangChain (`gerar_embeddings.py`)

Nesta etapa, usamos o modelo `all-MiniLM-L6-v2` da HuggingFace (via LangChain) para transformar os textos em **vetores semÃ¢nticos** e armazenÃ¡-los com FAISS.

### âœ¨ O que Ã© feito:

* Carregamento do CSV limpo
* VetorizaÃ§Ã£o dos textos com LangChain
* CriaÃ§Ã£o de um Ã­ndice FAISS
* Salvamento local para reuso posterior

### ğŸ“ Entrada esperada:

```
propostas_limpa.csv
```

Coluna: `propostas_processadas`

### â–¶ï¸ Como executar

```bash
python gerar_embeddings.py
```

### ğŸ§¾ Resultado:

Cria a pasta `faiss_index/` com o Ã­ndice vetorial salvo, roda-ser o cÃ³digo de acordo com a quantidade de arquivos 'csv' que se deseja processar. Esse Ã­ndice pode ser usado para:

* ğŸ” Buscar propostas semelhantes por tema
* ğŸ“Š Aplicar clusterizaÃ§Ã£o temÃ¡tica (KMeans, HDBSCAN)
* ğŸ’¬ Alimentar um chatbot com IA baseado em busca semÃ¢ntica (LangChain RAG)

---

## ğŸ“ Estrutura sugerida do projeto

```
ğŸ“¦ cluster-propostas/
â”œâ”€â”€ integracao.py                # PrÃ©-processamento textual
â”œâ”€â”€ gerar_embeddings.py          # GeraÃ§Ã£o de embeddings + FAISS
â”œâ”€â”€ propostas_limpa.csv          # Textos limpos prontos para vetorizaÃ§Ã£o
â”œâ”€â”€ faiss_index/                 # Armazenamento dos vetores
â”œâ”€â”€ README.md                    # DocumentaÃ§Ã£o do projeto
â”œâ”€â”€ requirements.txt             # Lista de dependÃªncias
```

---

## ğŸš€ PrÃ³ximos passos

* [ ] Aplicar clusterizaÃ§Ã£o com KMeans e HDBSCAN
* [ ] Visualizar clusters com UMAP e WordClouds
* [ ] Criar uma interface interativa para explorar os temas (Streamlit, React ou Jetpack Compose)
* [ ] LanÃ§ar um MVP do sistema "Participa+" para experimentaÃ§Ã£o cidadÃ£

```